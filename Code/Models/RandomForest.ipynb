{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3412875 entries, 0 to 3412874\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   station_id            int64  \n",
      " 1   Net_Flow              int64  \n",
      " 2   Split_hour            int64  \n",
      " 3   is_holiday            bool   \n",
      " 4   feels_like            float64\n",
      " 5   weather_Clear         int64  \n",
      " 6   weather_Clouds        int64  \n",
      " 7   weather_Drizzle       int64  \n",
      " 8   weather_Fog           int64  \n",
      " 9   weather_Haze          int64  \n",
      " 10  weather_Mist          int64  \n",
      " 11  weather_Rain          int64  \n",
      " 12  weather_Smoke         int64  \n",
      " 13  weather_Snow          int64  \n",
      " 14  weather_Thunderstorm  int64  \n",
      " 15  day_of_week           int64  \n",
      "dtypes: bool(1), float64(1), int64(14)\n",
      "memory usage: 393.8 MB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('Merged_Data_202101_202303_v3.csv')\n",
    "data_df = data_df.iloc[: , 1:]\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>Net_Flow</th>\n",
       "      <th>Split_hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>weather_Clear</th>\n",
       "      <th>weather_Clouds</th>\n",
       "      <th>weather_Drizzle</th>\n",
       "      <th>weather_Fog</th>\n",
       "      <th>weather_Haze</th>\n",
       "      <th>weather_Mist</th>\n",
       "      <th>weather_Rain</th>\n",
       "      <th>weather_Smoke</th>\n",
       "      <th>weather_Snow</th>\n",
       "      <th>weather_Thunderstorm</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id  Net_Flow  Split_hour  is_holiday  feels_like  weather_Clear  \\\n",
       "0           1        -1          22       False       -3.42              0   \n",
       "1           1        -1          21       False       -5.97              0   \n",
       "2           1        -1          16       False       -4.41              0   \n",
       "3           1        -1          16       False       -1.97              0   \n",
       "4           1        -1          15       False       -0.96              0   \n",
       "\n",
       "   weather_Clouds  weather_Drizzle  weather_Fog  weather_Haze  weather_Mist  \\\n",
       "0               1                0            0             0             0   \n",
       "1               0                0            0             0             0   \n",
       "2               0                0            0             0             0   \n",
       "3               0                0            0             0             0   \n",
       "4               1                0            0             0             0   \n",
       "\n",
       "   weather_Rain  weather_Smoke  weather_Snow  weather_Thunderstorm  \\\n",
       "0             0              0             0                     0   \n",
       "1             0              0             1                     0   \n",
       "2             1              0             0                     0   \n",
       "3             1              0             0                     0   \n",
       "4             0              0             0                     0   \n",
       "\n",
       "   day_of_week  \n",
       "0            3  \n",
       "1            3  \n",
       "2            2  \n",
       "3            3  \n",
       "4            6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_df[['station_id', 'Split_hour', 'day_of_week', 'is_holiday', 'feels_like']]\n",
    "y = data_df['Net_Flow']\n",
    "\n",
    "\n",
    "#X = pd.get_dummies(X, columns=['station_id', 'Split_hour', 'day_of_week', 'is_holiday', 'feels_like'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10, max_depth: 5, MSE:  7.0777, Time:  11.1475s\n",
      "n_estimators: 10, max_depth: 10, MSE:  6.4625, Time:  20.6535s\n",
      "n_estimators: 10, max_depth: 15, MSE:  6.1656, Time:  28.9572s\n",
      "n_estimators: 20, max_depth: 5, MSE:  7.0779, Time:  22.2771s\n",
      "n_estimators: 20, max_depth: 10, MSE:  6.4590, Time:  41.2716s\n",
      "n_estimators: 20, max_depth: 15, MSE:  6.1401, Time:  57.8288s\n",
      "n_estimators: 100, max_depth: 5, MSE:  7.0775, Time:  111.7889s\n",
      "n_estimators: 100, max_depth: 10, MSE:  6.4559, Time:  206.7005s\n",
      "n_estimators: 100, max_depth: 15, MSE:  6.1205, Time:  290.3190s\n",
      "Best MSE: 6.1205495863304815 with n_estimators = 100 and max_depth = 15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "n_estimators_range = [10, 20, 100]  \n",
    "max_depth_range = [5, 10, 15]    \n",
    "\n",
    "best_mse = float('inf')\n",
    "best_n = 0\n",
    "best_depth = 0\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    for depth in max_depth_range:\n",
    "        start_time = time.time()\n",
    "        model = RandomForestRegressor(n_estimators=n, max_depth=depth, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        time_inter = time.time() - start_time\n",
    "        print(f\"n_estimators: {n}, max_depth: {depth}, MSE: {mse: .4f}, Time: {time_inter: .4f}s\")\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_n = n\n",
    "            best_depth = depth\n",
    "\n",
    "print(f\"Best MSE: {best_mse} with n_estimators = {best_n} and max_depth = {best_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017\n",
      " -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017\n",
      " -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017\n",
      " -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017 -0.04601017]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "next_24_hours = pd.date_range(start=merged_df.index[-1], periods=24, freq='H')\n",
    "\n",
    "next_24_hours_data = {\n",
    "    'station_id': [1]*24,  \n",
    "    'hour': next_24_hours.hour,\n",
    "    'day_of_week': next_24_hours.dayofweek,\n",
    "    'is_holiday': next_24_hours.isin([pd.to_datetime(date) for date in holidays])\n",
    "}\n",
    "next_24_hours_df = pd.DataFrame(next_24_hours_data)\n",
    "\n",
    "all_categories = pd.get_dummies(X_train).columns\n",
    "\n",
    "\n",
    "next_24_hours_df = pd.get_dummies(next_24_hours_df)\n",
    "\n",
    "next_24_hours_df = next_24_hours_df.reindex(columns=all_categories, fill_value=0)\n",
    "\n",
    "predictions = model.predict(next_24_hours_df)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_csv('Merged_Data_202101_202303_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 20:31:07 WARN Utils: Your hostname, yuzhuorandeMacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.4.42 instead (on interface en0)\n",
      "24/04/19 20:31:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/04/19 20:31:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RandomForestTraining\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.9\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 20:31:19 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 1:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- Split_hour: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- is_holiday: boolean (nullable = true)\n",
      " |-- feels_like: double (nullable = true)\n",
      " |-- Net_Flow: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('Merged_Data_202101_202303_v3.csv', header=True, inferSchema=True)\n",
    "df = df.select(\"station_id\", \"Split_hour\", \"day_of_week\", \"is_holiday\", \"feels_like\", \"Net_Flow\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"is_holiday\", col(\"is_holiday\").cast(\"string\"))\n",
    "df = df.withColumn(\"Split_hour\", col(\"Split_hour\").cast(\"string\"))\n",
    "\n",
    "# First, ensure any categorical features are indexed if they're not already\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\")\n",
    "    for column in [\"station_id\", \"Split_hour\", \"day_of_week\", \"is_holiday\"]\n",
    "]\n",
    "# Now create a VectorAssembler to combine all features into one vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"station_id_index\", \"Split_hour_index\", \"day_of_week_index\", \"is_holiday_index\", \"feels_like\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "transformed_df = model.transform(df)\n",
    "\n",
    "(train_data, test_data) = transformed_df.randomSplit([0.6, 0.4], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/cxncnmt11hsbyfjjtpglf3kr0000gn/T/ipykernel_1991/3909058613.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTrees: 30, maxDepth: 5, MSE:  6.8612, Time:  30.4737s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 20:32:29 WARN DAGScheduler: Broadcasting large task binary with size 1374.0 KiB\n",
      "24/04/19 20:32:35 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/04/19 20:32:42 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/04/19 20:32:50 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n",
      "24/04/19 20:33:04 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "24/04/19 20:33:23 WARN DAGScheduler: Broadcasting large task binary with size 1333.8 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTrees: 30, maxDepth: 10, MSE:  6.1127, Time:  92.3623s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 20:34:18 WARN DAGScheduler: Broadcasting large task binary with size 1374.0 KiB\n",
      "24/04/19 20:34:25 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "24/04/19 20:34:34 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "24/04/19 20:34:44 WARN DAGScheduler: Broadcasting large task binary with size 6.6 MiB\n",
      "24/04/19 20:34:57 WARN DAGScheduler: Broadcasting large task binary with size 11.2 MiB\n",
      "24/04/19 20:35:18 WARN DAGScheduler: Broadcasting large task binary with size 1333.8 KiB\n",
      "24/04/19 20:35:22 WARN DAGScheduler: Broadcasting large task binary with size 13.6 MiB\n",
      "24/04/19 20:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1803.1 KiB\n",
      "24/04/19 20:35:39 WARN DAGScheduler: Broadcasting large task binary with size 12.8 MiB\n",
      "24/04/19 20:35:50 WARN DAGScheduler: Broadcasting large task binary with size 1811.1 KiB\n",
      "24/04/19 20:35:53 WARN DAGScheduler: Broadcasting large task binary with size 12.8 MiB\n",
      "24/04/19 20:36:00 WARN DAGScheduler: Broadcasting large task binary with size 1814.1 KiB\n",
      "24/04/19 20:36:05 WARN DAGScheduler: Broadcasting large task binary with size 12.9 MiB\n",
      "24/04/19 20:36:10 WARN DAGScheduler: Broadcasting large task binary with size 1813.3 KiB\n",
      "24/04/19 20:36:13 WARN DAGScheduler: Broadcasting large task binary with size 11.9 MiB\n",
      "24/04/19 20:36:18 WARN DAGScheduler: Broadcasting large task binary with size 1806.2 KiB\n",
      "24/04/19 20:36:21 WARN DAGScheduler: Broadcasting large task binary with size 17.6 MiB\n",
      "24/04/19 20:36:27 WARN DAGScheduler: Broadcasting large task binary with size 1811.2 KiB\n",
      "24/04/19 20:36:30 WARN DAGScheduler: Broadcasting large task binary with size 13.2 MiB\n",
      "24/04/19 20:36:36 WARN DAGScheduler: Broadcasting large task binary with size 1814.3 KiB\n",
      "24/04/19 20:36:41 WARN DAGScheduler: Broadcasting large task binary with size 13.6 MiB\n",
      "24/04/19 20:36:48 WARN DAGScheduler: Broadcasting large task binary with size 1810.4 KiB\n",
      "24/04/19 20:36:52 WARN DAGScheduler: Broadcasting large task binary with size 13.4 MiB\n",
      "24/04/19 20:36:57 WARN DAGScheduler: Broadcasting large task binary with size 1810.4 KiB\n",
      "24/04/19 20:37:01 WARN DAGScheduler: Broadcasting large task binary with size 16.1 MiB\n",
      "24/04/19 20:37:06 WARN DAGScheduler: Broadcasting large task binary with size 1830.9 KiB\n",
      "24/04/19 20:37:10 WARN DAGScheduler: Broadcasting large task binary with size 17.8 MiB\n",
      "24/04/19 20:37:18 WARN DAGScheduler: Broadcasting large task binary with size 1820.8 KiB\n",
      "24/04/19 20:37:22 WARN DAGScheduler: Broadcasting large task binary with size 16.1 MiB\n",
      "24/04/19 20:37:28 WARN DAGScheduler: Broadcasting large task binary with size 1818.4 KiB\n",
      "24/04/19 20:37:32 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "24/04/19 20:37:37 WARN DAGScheduler: Broadcasting large task binary with size 1801.6 KiB\n",
      "24/04/19 20:37:41 WARN DAGScheduler: Broadcasting large task binary with size 14.5 MiB\n",
      "24/04/19 20:37:47 WARN DAGScheduler: Broadcasting large task binary with size 1822.8 KiB\n",
      "24/04/19 20:37:51 WARN DAGScheduler: Broadcasting large task binary with size 19.1 MiB\n",
      "24/04/19 20:38:01 WARN DAGScheduler: Broadcasting large task binary with size 1811.9 KiB\n",
      "24/04/19 20:38:04 WARN DAGScheduler: Broadcasting large task binary with size 15.3 MiB\n",
      "24/04/19 20:38:10 WARN DAGScheduler: Broadcasting large task binary with size 1798.0 KiB\n",
      "24/04/19 20:38:14 WARN DAGScheduler: Broadcasting large task binary with size 14.8 MiB\n",
      "24/04/19 20:38:25 WARN DAGScheduler: Broadcasting large task binary with size 1813.7 KiB\n",
      "24/04/19 20:38:30 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB\n",
      "24/04/19 20:38:36 WARN DAGScheduler: Broadcasting large task binary with size 1807.2 KiB\n",
      "24/04/19 20:38:40 WARN DAGScheduler: Broadcasting large task binary with size 16.2 MiB\n",
      "24/04/19 20:38:48 WARN DAGScheduler: Broadcasting large task binary with size 1820.8 KiB\n",
      "24/04/19 20:38:53 WARN DAGScheduler: Broadcasting large task binary with size 14.3 MiB\n",
      "24/04/19 20:39:00 WARN DAGScheduler: Broadcasting large task binary with size 1804.3 KiB\n",
      "24/04/19 20:39:03 WARN DAGScheduler: Broadcasting large task binary with size 17.5 MiB\n",
      "24/04/19 20:39:13 WARN DAGScheduler: Broadcasting large task binary with size 1806.4 KiB\n",
      "24/04/19 20:39:18 WARN DAGScheduler: Broadcasting large task binary with size 13.0 MiB\n",
      "24/04/19 20:39:25 WARN DAGScheduler: Broadcasting large task binary with size 1790.2 KiB\n",
      "24/04/19 20:39:29 WARN DAGScheduler: Broadcasting large task binary with size 10.2 MiB\n",
      "24/04/19 20:39:34 WARN DAGScheduler: Broadcasting large task binary with size 1159.9 KiB\n",
      "24/04/19 20:39:37 WARN DAGScheduler: Broadcasting large task binary with size 9.1 MiB\n",
      "24/04/19 20:39:41 WARN DAGScheduler: Broadcasting large task binary with size 1466.1 KiB\n",
      "24/04/19 20:39:44 WARN DAGScheduler: Broadcasting large task binary with size 12.8 MiB\n",
      "24/04/19 20:39:50 WARN DAGScheduler: Broadcasting large task binary with size 1803.0 KiB\n",
      "24/04/19 20:39:55 WARN DAGScheduler: Broadcasting large task binary with size 13.2 MiB\n",
      "24/04/19 20:40:01 WARN DAGScheduler: Broadcasting large task binary with size 1810.3 KiB\n",
      "24/04/19 20:40:06 WARN DAGScheduler: Broadcasting large task binary with size 7.1 MiB\n",
      "24/04/19 20:40:09 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "24/04/19 20:40:13 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "[Stage 138:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTrees: 30, maxDepth: 15, MSE:  5.8480, Time:  420.5069s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "# Possible values for numTrees and maxDepth\n",
    "numTrees_list = [30]\n",
    "maxDepth_list = [5, 10, 15]\n",
    "\n",
    "# Initialize the evaluator\n",
    "evaluator_mse = RegressionEvaluator(labelCol=\"Net_Flow\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(columns=[\"numTrees\", \"maxDepth\", \"MSE\", \"Time\"])\n",
    "\n",
    "for num in numTrees_list:\n",
    "    for depth in maxDepth_list:\n",
    "        start_time = time.time()\n",
    "        rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"Net_Flow\", numTrees=num, maxDepth=depth, maxBins=1000, seed=42)\n",
    "        rf_model = rf.fit(train_data)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = rf_model.transform(test_data)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        mse = evaluator_mse.evaluate(predictions)\n",
    "        time_inter = time.time() - start_time\n",
    "        print(f\"numTrees: {num}, maxDepth: {depth}, MSE: {mse: .4f}, Time: {time_inter: .4f}s\")\n",
    "        # Print and collect the results\n",
    "        new_row = pd.DataFrame({\"numTrees\": [num], \"maxDepth\": [depth], \"MSE\": [mse], \"Time\": [time_inter]})\n",
    "        results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "#print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark with weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrees</th>\n",
       "      <th>maxDepth</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6.908905</td>\n",
       "      <td>23.803790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.159883</td>\n",
       "      <td>34.212571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5.934817</td>\n",
       "      <td>104.680240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>6.894684</td>\n",
       "      <td>26.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>6.144721</td>\n",
       "      <td>56.503823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>5.867577</td>\n",
       "      <td>239.560308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>6.854832</td>\n",
       "      <td>103.332939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  numTrees maxDepth       MSE        Time\n",
       "0       10        5  6.908905   23.803790\n",
       "1       10       10  6.159883   34.212571\n",
       "2       10       15  5.934817  104.680240\n",
       "3       20        5  6.894684   26.530400\n",
       "4       20       10  6.144721   56.503823\n",
       "5       20       15  5.867577  239.560308\n",
       "6      100        5  6.854832  103.332939"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrees</th>\n",
       "      <th>maxDepth</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>6.861225</td>\n",
       "      <td>30.473653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>6.112688</td>\n",
       "      <td>92.362313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>5.847989</td>\n",
       "      <td>420.506886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  numTrees maxDepth       MSE        Time\n",
       "0       30        5  6.861225   30.473653\n",
       "1       30       10  6.112688   92.362313\n",
       "2       30       15  5.847989  420.506886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark without weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   numTrees maxDepth       MSE\n",
      "0         5        3  7.155212\n",
      "1         5        5  6.779841\n",
      "2         5       10  6.269571\n",
      "3         5       15  6.215765\n",
      "4        10        3  7.148010\n",
      "5        10        5  6.866187\n",
      "6        10       10  6.261236\n",
      "7        10       15  6.197606\n",
      "8        20        3  7.095159\n",
      "9        20        5  6.787787\n",
      "10       20       10  6.257980\n",
      "11       20       15  6.187825\n"
     ]
    }
   ],
   "source": [
    "print(results)##without weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
